# ERNIE TensorRT Inference

This project demonstrates how to accelerate inference for Baiduâ€™s ERNIE model (a BERT-style transformer) using NVIDIA TensorRT. By optimizing transformer layers and fusing QKV projections, the implementation achieves significantly reduced latency and memory usage, making it suitable for deployment in real-time NLP systems.
